{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b563e5cd-6d7f-4425-9f89-fc04c086a667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import hilbert\n",
    "import time\n",
    "\n",
    "# Define num_signals before using it as a default argument\n",
    "num_signals = 8\n",
    "\n",
    "# Define the features dictionary with the required values\n",
    "features = {\n",
    "    \"min_volt\": 1e-6,  # 1 microvolt\n",
    "    \"max_volt\": 8e-6,  # 8 microvolts\n",
    "    \"variability_factor\": 0.1,  # Direct mapping of player movement to variability factor, normalized to a 0-1 scale\n",
    "    \"variance\": 0.01,  # Mapping door state to variance feature\n",
    "    \"std_dev\": 0.05,  # Mapping enemy type to standard deviation feature\n",
    "    \"rms_value\": 0.02,  # Player health state affects the RMS value feature\n",
    "    \"num_peaks\": 5,  # Number of peaks determined by exploring states\n",
    "    \"peak_height\": 0.05,  # Peak height influenced by level state\n",
    "    \"fractal_dimension\": 1.5,  # Action states influence the fractal dimension\n",
    "    \"window_size\": 10,  # Window size feature influenced by wall states\n",
    "    \"target_rate\": 0.1,  # Target rate is determined by the presence of any enemy type\n",
    "    \"min_freq\": 0.5,  # Minimum frequency affected by player movement, demonstrating a range for frequency based on movement\n",
    "    \"max_freq\": 1.5,  # Maximum frequency influenced by player health state, indicating a dynamic range based on health\n",
    "    \"blend_factor\": 0.2,  # Static blend factor as a static state\n",
    "    \"global_sync_level\": 0.1,  # Global sync level determined by action state, reflecting synchronization needs\n",
    "    \"pairwise_sync_level\": 0.2,  # Pairwise sync level affected by door state, indicating sync adjustments based on environmental factors\n",
    "    \"sync_factor\": 0.05,  # Sync factor as a static value for simplicity\n",
    "    \"influence_factor\": 0.1,  # Influence factor derived from enemy type, representing external influence levels\n",
    "    \"max_influence\": 0.02,  # Maximum influence as a static maximum for the presence of any enemy\n",
    "    \"centroid_factor\": 0.1,  # Centroid factor and edge density factor as placeholders for sensory data encoding\n",
    "    \"edge_density_factor\": 0.2,  # Centroid factor and edge density factor as placeholders for sensory data encoding\n",
    "    \"complexity_factor\": 0.1,  # Example value for complexity factor in FFT\n",
    "    \"evolution_rate\": 0.05,  # Evolution rate as a static value for dynamic environmental changes\n",
    "    \"low_freq\": 0.5,  # Low frequency ranges influenced by exploring states\n",
    "    \"high_freq\": 2.0,  # High frequency ranges influenced by level states\n",
    "    \"causality_strength\": 0.1,  # Causality strength as a static value for interaction effects\n",
    "    \"num_imfs\": 5,  # Number of intrinsic mode functions (IMFs) as a static value for interaction effects\n",
    "}\n",
    "\n",
    "# Function to generate base ECoG-like signals within the specified range\n",
    "def generate_ecog_like_base_signals(length, num_signals=num_signals):\n",
    "    signals = np.random.uniform(min_volt, max_volt, (num_signals, length))\n",
    "    return signals\n",
    "\n",
    "# Function to scale signals to a specific bit depth\n",
    "def scale_signals_to_bit_depth(modified_signals, bit_depth):\n",
    "    # Ensure modified_signals is a floating-point array to allow for intermediate float operations\n",
    "    modified_signals = modified_signals.astype(np.float64)\n",
    "    \n",
    "    # Normalize signals to range [0, 1]\n",
    "    min_signal = np.min(modified_signals)\n",
    "    max_signal = np.max(modified_signals)\n",
    "    normalized_signals = (modified_signals - min_signal) / (max_signal - min_signal)\n",
    "    \n",
    "    # Scale to the new range determined by bit depth\n",
    "    max_value = (2 ** bit_depth) - 1\n",
    "    modified_signals = normalized_signals * max_value\n",
    "\n",
    "    return modified_signals\n",
    "\n",
    "# Function to apply amplitude variability while keeping the signals within the specified range\n",
    "def apply_amplitude_variability(modified_signals, variability_factor):\n",
    "    # Apply amplitude variability to each signal individually\n",
    "    for i in range(modified_signals.shape[0]):\n",
    "        # Calculate the scaling factor for each signal\n",
    "        current_std = np.std(modified_signals[i])\n",
    "        if current_std == 0:\n",
    "            continue  # Skip if standard deviation is zero to avoid division by zero\n",
    "        scaling_factor = np.sqrt(variability_factor) / current_std\n",
    "\n",
    "        # Generate scaled noise for each signal\n",
    "        scaled_noise = np.random.normal(0, scaling_factor, modified_signals.shape[1])\n",
    "\n",
    "        # Add the scaled noise to the signal\n",
    "        modified_signals[i] += scaled_noise\n",
    "\n",
    "    # Scale the entire signal set to fit within the min_volt and max_volt range\n",
    "    max_signal = np.max(modified_signals)\n",
    "    min_signal = np.min(modified_signals)\n",
    "    modified_signals = ((modified_signals - min_signal) / (max_signal - min_signal)) * (max_volt - min_volt) + min_volt\n",
    "\n",
    "    return modified_signals\n",
    "\n",
    "# Function to apply variance while keeping the signals within the specified range\n",
    "def apply_variance(modified_signals, variance):\n",
    "    for i in range(modified_signals.shape[0]):\n",
    "        # Generate noise for each signal based on the specified variance\n",
    "        noise = np.random.normal(0, np.sqrt(variance), modified_signals.shape[1])\n",
    "\n",
    "        # Add the noise to the signal\n",
    "        modified_signals[i] += noise\n",
    "\n",
    "    # Scale the entire signal set to fit within the min_volt and max_volt range\n",
    "    max_signal = np.max(modified_signals)\n",
    "    min_signal = np.min(modified_signals)\n",
    "    modified_signals = ((modified_signals - min_signal) / (max_signal - min_signal)) * (max_volt - min_volt) + min_volt\n",
    "\n",
    "    return modified_signals\n",
    "\n",
    "# Function to apply signal with standard deviation while keeping the signals within the specified range\n",
    "def apply_signal_with_std(modified_signals, std_dev):\n",
    "    for i in range(modified_signals.shape[0]):\n",
    "        # Calculate the scaling factor for each individual signal\n",
    "        current_std = np.std(modified_signals[i])\n",
    "        if current_std == 0:\n",
    "            continue  # Skip if standard deviation is zero to avoid division by zero\n",
    "        scaling_factor = std_dev / current_std\n",
    "\n",
    "        # Apply the scaled noise to each individual signal\n",
    "        modified_signals[i] += np.random.normal(0, scaling_factor * std_dev, modified_signals.shape[1])\n",
    "\n",
    "    # Scale the entire signal set to fit within the min_volt and max_volt range\n",
    "    max_signal = np.max(modified_signals)\n",
    "    min_signal = np.min(modified_signals)\n",
    "    modified_signals = ((modified_signals - min_signal) / (max_signal - min_signal)) * (max_volt - min_volt) + min_volt\n",
    "\n",
    "    return modified_signals\n",
    "\n",
    "# Function to apply signal with RMS value\n",
    "def apply_signal_with_rms(modified_signals, rms_value):\n",
    "    current_rms = np.sqrt(np.mean(modified_signals**2, axis=1, keepdims=True))\n",
    "    scaling_factor = np.minimum(1.0, rms_value / current_rms)\n",
    "    modified_signals *= scaling_factor\n",
    "    return modified_signals\n",
    "\n",
    "# Function to add peaks\n",
    "def add_peaks(modified_signals, num_peaks, peak_height):\n",
    "    if len(modified_signals) == 0:\n",
    "        raise ValueError(\"Input modified_signals array must not be empty\")\n",
    "    num_signals, signal_length = modified_signals.shape\n",
    "    scaling_factor = np.maximum(min_volt / np.min(modified_signals), max_volt / np.max(modified_signals))\n",
    "    \n",
    "    for i in range(num_signals):\n",
    "        for _ in range(num_peaks):\n",
    "            peak_position = np.random.randint(0, signal_length)\n",
    "            modified_signals[i, peak_position] += peak_height * scaling_factor\n",
    "            # Ensure that the modified signal does not exceed the specified range\n",
    "            modified_signals[i, peak_position] = np.clip(modified_signals[i, peak_position], min_volt, max_volt)\n",
    "            \n",
    "    return modified_signals\n",
    "\n",
    "# Function to apply moving average\n",
    "def apply_moving_average(modified_signals, window_size):  \n",
    "    for i in range(len(modified_signals)):\n",
    "        length = len(modified_signals[i])\n",
    "        if length >= window_size:\n",
    "            cumsum_vec = np.cumsum(np.insert(modified_signals[i], 0, 0))\n",
    "            moving_average = (cumsum_vec[window_size:] - cumsum_vec[:-window_size]) / window_size\n",
    "            # Apply the moving average only to the middle part of the signal\n",
    "            modified_signals[i, window_size//2:-window_size//2+1] = moving_average\n",
    "    return modified_signals\n",
    "\n",
    "# Function to apply fractal structure\n",
    "def apply_fractal_structure(modified_signals, fractal_dimension):\n",
    "    length = modified_signals.shape[1]\n",
    "    fBm_signal = np.zeros_like(modified_signals)\n",
    "\n",
    "    # Calculate Hurst exponent from fractal dimension\n",
    "    hurst_exponent = 2 - fractal_dimension\n",
    "\n",
    "    for i in range(1, length):\n",
    "        scale = (i ** (2 * hurst_exponent)) - ((i-1) ** (2 * hurst_exponent))\n",
    "        fBm_signal[:, i] = fBm_signal[:, i-1] + np.random.normal(0, np.sqrt(scale), modified_signals.shape[0])\n",
    "\n",
    "    # Scale fBm_signal to match the original signal's range\n",
    "    max_signal = np.max(fBm_signal, axis=1, keepdims=True)\n",
    "    min_signal = np.min(fBm_signal, axis=1, keepdims=True)\n",
    "    fBm_signal = (fBm_signal - min_signal) / (max_signal - min_signal)\n",
    "    fBm_signal *= (max_volt - min_volt)\n",
    "    fBm_signal += min_volt\n",
    "\n",
    "    return modified_signals\n",
    "    \n",
    "# Function to apply zero-crossing rate\n",
    "def apply_zero_crossing_rate(modified_signals, target_rate):\n",
    "    def calculate_zero_crossing_rate(sig):\n",
    "        zero_crossings = np.where(np.diff(np.sign(sig)))[0]\n",
    "        return len(zero_crossings) / len(sig)\n",
    "\n",
    "    for i in range(len(modified_signals)):\n",
    "        current_rate = calculate_zero_crossing_rate(modified_signals[i])\n",
    "        factor = target_rate / current_rate if current_rate > 0 else 1.0\n",
    "        modified_signals[i] *= factor\n",
    "    return modified_signals\n",
    "\n",
    "# Function to apply Arnold tongues\n",
    "def apply_arnold_tongues(modified_signals, min_freq, max_freq, blend_factor):\n",
    "    num_signals, signal_length = modified_signals.shape\n",
    "\n",
    "    for i in range(num_signals):\n",
    "        # Generate a random K within a more controlled range\n",
    "        K = np.random.uniform(0.1 * max_volt, 0.5 * max_volt)  # Reduced amplitude range\n",
    "\n",
    "        # Generate an Arnold tongue pattern with the specified frequency range\n",
    "        omega = np.random.uniform(min_freq, max_freq)  # Use the provided frequency range\n",
    "        t = np.linspace(0, 2 * np.pi, signal_length)\n",
    "        arnold_tongue_pattern = np.sin(t * omega) * K\n",
    "        \n",
    "        # Introduce additional harmonics or noise to the pattern\n",
    "        harmonics = np.random.choice([2, 3, 4], size=1)\n",
    "        noise = np.random.uniform(-0.1 * K, 0.1 * K, size=signal_length)\n",
    "        arnold_tongue_pattern += (np.sin(t * omega * harmonics) + noise) * K * 0.5\n",
    "\n",
    "        # Blend the Arnold tongue pattern with the original signal\n",
    "        modified_signals[i, :] = (1 - blend_factor) * modified_signals[i, :] + blend_factor * arnold_tongue_pattern\n",
    "\n",
    "    # Normalize the signals\n",
    "    max_signal = np.max(modified_signals)\n",
    "    min_signal = np.min(modified_signals)\n",
    "    normalized_signals = ((modified_signals - min_signal) / (max_signal - min_signal)) * (max_volt - min_volt) + min_volt\n",
    "\n",
    "    return normalized_signals\n",
    "\n",
    "def apply_phase_synchronization(modified_signals, global_sync_level, pairwise_sync_level, sync_factor=0.05):\n",
    "    num_signals, length = modified_signals.shape\n",
    "    common_phase = np.linspace(0, 2 * np.pi * global_sync_level, length)\n",
    "\n",
    "    # Apply global synchronization\n",
    "    for i in range(num_signals):\n",
    "        signal_fft = np.fft.fft(modified_signals[i])\n",
    "        amplitude = np.abs(signal_fft)\n",
    "        phase = np.angle(signal_fft)\n",
    "        \n",
    "        # Adjust phase globally\n",
    "        global_phase_shift = sync_factor * np.interp(common_phase, (common_phase.min(), common_phase.max()), (-np.pi, np.pi))\n",
    "        adjusted_phase = phase + global_phase_shift\n",
    "        modified_signals[i] = np.fft.ifft(amplitude * np.exp(1j * adjusted_phase)).real\n",
    "\n",
    "    # Apply pairwise synchronization more selectively\n",
    "    for i in range(num_signals):\n",
    "        for j in range(i + 1, num_signals):\n",
    "            # Calculate pairwise phase difference\n",
    "            phase_diff = np.angle(np.fft.fft(modified_signals[i])) - np.angle(np.fft.fft(modified_signals[j]))\n",
    "            phase_diff_adjustment = np.interp(phase_diff, (-np.pi, np.pi), (-pairwise_sync_level, pairwise_sync_level))\n",
    "\n",
    "            # Apply the phase adjustment selectively\n",
    "            signal_fft_i = np.fft.fft(modified_signals[i])\n",
    "            signal_fft_j = np.fft.fft(modified_signals[j])\n",
    "            adjusted_phase_i = np.angle(signal_fft_i) + phase_diff_adjustment * sync_factor\n",
    "            adjusted_phase_j = np.angle(signal_fft_j) - phase_diff_adjustment * sync_factor\n",
    "\n",
    "            # Apply the adjusted phases\n",
    "            modified_signals[i] = np.fft.ifft(np.abs(signal_fft_i) * np.exp(1j * adjusted_phase_i)).real\n",
    "            modified_signals[j] = np.fft.ifft(np.abs(signal_fft_j) * np.exp(1j * adjusted_phase_j)).real\n",
    "\n",
    "    # Rescale the signals\n",
    "    max_signal = np.max(modified_signals)\n",
    "    min_signal = np.min(modified_signals)\n",
    "    modified_signals = ((modified_signals - min_signal) / (max_signal - min_signal)) * (max_volt - min_volt) + min_volt\n",
    "\n",
    "    return modified_signals\n",
    "\n",
    "def apply_transfer_entropy(modified_signals, influence_factor, max_influence):\n",
    "    num_signals = len(modified_signals)\n",
    "    max_length = max(len(signal) for signal in modified_signals)\n",
    "    \n",
    "    # Normalize interaction weights to sum up to the influence factor\n",
    "    interaction_weights = np.random.uniform(0, 1, (num_signals, num_signals))\n",
    "    interaction_weights /= interaction_weights.sum(axis=1, keepdims=True)\n",
    "    interaction_weights *= influence_factor\n",
    "    \n",
    "    for i in range(1, max_length):\n",
    "        # Calculate the influenced signals\n",
    "        influenced_signals = np.dot(interaction_weights, [signal[i - 1] if i < len(signal) else signal[-1] for signal in modified_signals])\n",
    "        \n",
    "        # Calculate the maximum possible influence to stay within the specified voltage range\n",
    "        max_possible_influence = (max_volt - min_volt) / max_length\n",
    "        \n",
    "        # Scale down the influenced signals if necessary\n",
    "        if np.max(np.abs(influenced_signals)) > max_possible_influence:\n",
    "            scaling_factor = max_possible_influence / np.max(np.abs(influenced_signals))\n",
    "            influenced_signals *= scaling_factor\n",
    "        \n",
    "        # Add the influenced signals to the original signals\n",
    "        for j in range(num_signals):\n",
    "            if i < len(modified_signals[j]):\n",
    "                modified_signals[j][i] += influenced_signals[j]\n",
    "\n",
    "    return modified_signals\n",
    "\n",
    "# Function to apply Hilbert-Huang transform\n",
    "def apply_hilbert_huang(modified_signals):\n",
    "    for i in range(len(modified_signals)):\n",
    "        signal = modified_signals[i]\n",
    "        \n",
    "        # Calculate the amplitude for the low-frequency component (lowest 10%)\n",
    "        low_freq_amplitude = 0.05 * (max_volt - min_volt)\n",
    "        low_freq_signal = low_freq_amplitude * np.sin(2 * np.pi * 0.1 * np.arange(len(signal)))\n",
    "        \n",
    "        # Calculate the amplitude for the high-frequency component (highest 10%)\n",
    "        high_freq_amplitude = 0.05 * (max_volt - min_volt)\n",
    "        high_freq_noise = high_freq_amplitude * np.random.randn(len(signal))\n",
    "        \n",
    "        # Combine the components\n",
    "        modulated_signal = signal + low_freq_signal + high_freq_noise\n",
    "\n",
    "        # Clip the signal to the specified range\n",
    "        modulated_signal = np.clip(modulated_signal, min_volt, max_volt)\n",
    "\n",
    "        modified_signals[i] = modulated_signal\n",
    "\n",
    "    return modified_signals\n",
    "\n",
    "# Function to apply spectral centroids\n",
    "def apply_spectral_centroids(modified_signals, centroid_factor, edge_density_factor):\n",
    "    for i in range(modified_signals.shape[0]):\n",
    "        fft_spectrum = np.fft.fft(modified_signals[i])\n",
    "        freq = np.fft.fftfreq(len(modified_signals[i]))\n",
    "        centroid = np.sum(freq * np.abs(fft_spectrum)) / np.sum(np.abs(fft_spectrum))\n",
    "        edge_density = np.sum(np.abs(np.diff(fft_spectrum))) / np.sum(np.abs(fft_spectrum))\n",
    "        adjusted_spectrum = fft_spectrum * (centroid_factor * centroid + edge_density_factor * edge_density)\n",
    "        modified_signals[i] = np.fft.ifft(adjusted_spectrum).real\n",
    "    return modified_signals\n",
    "    \n",
    "# Function to apply dynamic time warping\n",
    "def apply_dynamic_time_warping(modified_signals, reference_signal, warping_factor, min_volt, max_volt):\n",
    "    modified_signals_aligned = []\n",
    "\n",
    "    reference_signal = np.array(reference_signal)  # Convert the reference signal to a numpy array\n",
    "\n",
    "    for signal in modified_signals:\n",
    "        signal = np.array(signal)  # Convert the signal to a numpy array\n",
    "\n",
    "        # Perform dynamic time warping\n",
    "        signal_length = len(signal)\n",
    "        time_vector = np.linspace(0, 1, signal_length)\n",
    "        reference_time_vector = np.linspace(0, 1, len(reference_signal)) * warping_factor\n",
    "        modified_signal = np.interp(time_vector, reference_time_vector, reference_signal)\n",
    "\n",
    "        # Normalize the signal to stay within the desired range\n",
    "        current_min = np.min(modified_signal)\n",
    "        current_max = np.max(modified_signal)\n",
    "\n",
    "        # Calculate the scaling factor to keep the signal within the specified range\n",
    "        scaling_factor = (max_volt - min_volt) / (current_max - current_min)\n",
    "\n",
    "        # Apply the scaling factor while preserving the signal's shape\n",
    "        modified_signal = (modified_signal - current_min) * scaling_factor + min_volt\n",
    "\n",
    "        modified_signals_aligned.append(modified_signal)\n",
    "\n",
    "    return np.array(modified_signals)\n",
    "    \n",
    "def apply_fft(modified_signals, complexity_factor):\n",
    "    modified_signals_complexity = []\n",
    "\n",
    "    for signal in modified_signals:\n",
    "        # Apply FFT to each signal\n",
    "        spectrum = np.fft.fft(signal)\n",
    "        freq = np.fft.fftfreq(len(signal))\n",
    "\n",
    "        # Calculate the scaling factor to keep the signal within the range\n",
    "        current_max = np.max(signal)\n",
    "        current_min = np.min(signal)\n",
    "        scaling_factor = max_volt / (current_max - current_min)\n",
    "\n",
    "        # Apply complexity modification\n",
    "        modified_spectrum = spectrum * (1 + np.random.randn(len(spectrum)) * complexity_factor)\n",
    "        \n",
    "        # Transform back to time domain\n",
    "        modified_signal = np.fft.ifft(modified_spectrum).real\n",
    "        \n",
    "        # Scale the signal while preserving the range\n",
    "        modified_signal = (modified_signal - current_min) * scaling_factor + min_volt\n",
    "        modified_signals_complexity.append(modified_signal)\n",
    "\n",
    "    return np.array(modified_signals)\n",
    "\n",
    "def apply_signal_evolution(modified_signals, evolution_rate):\n",
    "    modified_signals_evolution = np.zeros_like(modified_signals)\n",
    "    for i in range(modified_signals.shape[0]):\n",
    "        modified_signals_evolution[i, 0] = np.random.randn()\n",
    "        for t in range(1, modified_signals.shape[1]):\n",
    "            modified_signals_evolution[i, t] = modified_signals_evolution[i, t - 1] + evolution_rate * np.random.randn()\n",
    "    return modified_signals\n",
    "\n",
    "def apply_phase_amplitude_coupling(modified_signals, low_freq, high_freq):\n",
    "    modified_signals_pac = np.zeros_like(modified_signals)\n",
    "    time = np.linspace(0, 1, modified_signals.shape[1])\n",
    "    for i in range(modified_signals.shape[0]):\n",
    "        low_freq_signal = np.sin(2 * np.pi * low_freq * time)\n",
    "        high_freq_signal = np.sin(2 * np.pi * high_freq * time)\n",
    "        modified_signals_pac[i] = (1 + low_freq_signal) * high_freq_signal\n",
    "    return modified_signals\n",
    "\n",
    "def apply_granger_causality(modified_signals, causality_strength):\n",
    "    modified_signals_granger = np.copy(modified_signals)\n",
    "    num_signals, signal_length = modified_signals.shape\n",
    "    for i in range(1, num_signals):\n",
    "        for j in range(num_signals):\n",
    "            if i != j:\n",
    "                causal_effect = modified_signals[j, :-i] * causality_strength\n",
    "                modified_signals_granger[i, i:] += causal_effect\n",
    "    return modified_signals\n",
    "\n",
    "def apply_multivariate_empirical_mode_decomposition(modified_signals, num_imfs):\n",
    "    num_channels, signal_length = modified_signals.shape\n",
    "    memd_signals = np.zeros((num_channels, num_imfs, signal_length))\n",
    "    for channel in range(num_channels):\n",
    "        for imf_idx in range(num_imfs):\n",
    "            imf = np.sin(2 * np.pi * (imf_idx + 1) * np.linspace(0, 1, signal_length))\n",
    "            amplitude_scaling = np.random.uniform(0.5, 2.0)\n",
    "            memd_signals[channel, imf_idx, :] = amplitude_scaling * imf\n",
    "    modified_signals_memd = modified_signals + np.sum(memd_signals, axis=1)\n",
    "    return modified_signals\n",
    "\n",
    "def apply_normalized_states(modified_signals, modification_factor, matrix_size, value_range, num_matrices, eigenvalue_subset):\n",
    "    num_signals, signal_length = modified_signals.shape\n",
    "    modified_signals = modified_signals.copy()\n",
    "\n",
    "    # Function to generate a parameterized random Hermitian matrix\n",
    "    def generate_parameterized_hermitian_matrix(size, value_range):\n",
    "        A = np.random.uniform(value_range[0], value_range[1], (size, size)) + \\\n",
    "            1j * np.random.uniform(value_range[0], value_range[1], (size, size))\n",
    "        return A + A.conj().T\n",
    "\n",
    "    density_diagonals = []\n",
    "    for _ in range(num_matrices):\n",
    "        hermitian_matrix = generate_parameterized_hermitian_matrix(matrix_size, value_range)\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(hermitian_matrix)\n",
    "        eigenvalues = eigenvalues[eigenvalue_subset]\n",
    "        eigenvectors = eigenvectors[:, eigenvalue_subset]\n",
    "        density_matrix = np.dot(eigenvectors, np.dot(np.diag(eigenvalues), eigenvectors.T.conj()))\n",
    "        density_diagonal = np.diag(density_matrix).real\n",
    "        density_diagonals.append(density_diagonal)\n",
    "\n",
    "    # Apply modifications using the density diagonals\n",
    "    for i, signal in enumerate(modified_signals):\n",
    "        density_diagonal = density_diagonals[i % len(density_diagonals)]\n",
    "        signal_modification = np.interp(signal, (np.min(signal), np.max(signal)), (np.min(density_diagonal), np.max(density_diagonal)))\n",
    "        modified_signals[i] = (1 - modification_factor) * signal + modification_factor * signal_modification\n",
    "\n",
    "    # Normalize the signals\n",
    "    max_signal = np.max(modified_signals)\n",
    "    min_signal = np.min(modified_signals)\n",
    "    modified_signals = ((modified_signals - min_signal) / (max_signal - min_signal)) * (max_volt - min_volt) + min_volt\n",
    "\n",
    "    return modified_signals\n",
    "\n",
    "def final_modified_scale_signals_to_bit_depth(modified_signals, bit_depth):\n",
    "    # Assuming that the desired final range is defined by global variables min_volt and max_volt\n",
    "    min_val, max_val = min_volt, max_volt\n",
    "\n",
    "    # Calculate the current range of the signals\n",
    "    max_signal = np.max(modified_signals)\n",
    "    min_signal = np.min(modified_signals)\n",
    "\n",
    "    # Scale the signals to the specified bit depth\n",
    "    # The formula maps the current range to the desired range [min_val, max_val]\n",
    "    scaled_signals = ((modified_signals - min_signal) / (max_signal - min_signal)) * (max_val - min_val) + min_val\n",
    "\n",
    "    return scaled_signals\n",
    "\n",
    "min_volt = features[\"min_volt\"]\n",
    "max_volt = features[\"max_volt\"]\n",
    "\n",
    "# Define the list of transformation functions using features\n",
    "transformations = [\n",
    "    lambda x: scale_signals_to_bit_depth(x, bit_depth),\n",
    "    lambda x: apply_amplitude_variability(x, features[\"variability_factor\"]),\n",
    "    lambda x: apply_variance(x, features[\"variance\"]),\n",
    "    lambda x: apply_signal_with_std(x, features[\"std_dev\"]),\n",
    "    lambda x: apply_signal_with_rms(x, features[\"rms_value\"]),\n",
    "    lambda x: add_peaks(x, features[\"num_peaks\"], features[\"peak_height\"]),\n",
    "    lambda x: apply_fractal_structure(x, features[\"fractal_dimension\"]),\n",
    "    lambda x: apply_moving_average(x, features[\"window_size\"]),\n",
    "    lambda x: apply_zero_crossing_rate(x, features[\"target_rate\"]),\n",
    "    lambda x: apply_arnold_tongues(x, features[\"min_freq\"], features[\"max_freq\"], features[\"blend_factor\"]),\n",
    "    lambda x: apply_phase_synchronization(x, features[\"global_sync_level\"], features[\"pairwise_sync_level\"], features[\"sync_factor\"]),\n",
    "    lambda x: apply_transfer_entropy(x, features[\"influence_factor\"], features[\"max_influence\"]),\n",
    "    lambda x: apply_hilbert_huang(x),\n",
    "    lambda x: apply_spectral_centroids(x, features[\"centroid_factor\"], features[\"edge_density_factor\"]),\n",
    "    lambda x: apply_dynamic_time_warping(x, reference_signal=np.mean(x, axis=0), warping_factor=0.5, min_volt=min_volt, max_volt=max_volt),\n",
    "    lambda x: apply_fft(x, features[\"complexity_factor\"]),\n",
    "    lambda x: apply_signal_evolution(x, features[\"evolution_rate\"]),\n",
    "    lambda x: apply_phase_amplitude_coupling(x, features[\"low_freq\"], features[\"high_freq\"]),\n",
    "    lambda x: apply_granger_causality(x, features[\"causality_strength\"]),\n",
    "    lambda x: apply_multivariate_empirical_mode_decomposition(x, features[\"num_imfs\"]),\n",
    "    lambda x: apply_normalized_states(x, modification_factor=0.1, matrix_size=10, value_range=(-1, 1), num_matrices=5, eigenvalue_subset=slice(0, 5)),\n",
    "]\n",
    "\n",
    "# Main function to generate and transform signals\n",
    "def generate_transformed_signals(signal_length, num_signals, transformation_functions):\n",
    "    modified_signals = generate_ecog_like_base_signals(signal_length, num_signals)\n",
    "\n",
    "    for transform in transformation_functions:\n",
    "        modified_signals = transform(modified_signals)\n",
    "        # Convert list to NumPy array if necessary\n",
    "        if isinstance(modified_signals, list):\n",
    "            modified_signals = np.array(modified_signals)\n",
    "\n",
    "        if np.isnan(modified_signals).any() or np.isinf(modified_signals).any():\n",
    "            print(f\"NaNs or Infinities found after {transform.__name__}\")\n",
    "        print(f\"Range after {transform.__name__}: {modified_signals.min()} to {modified_signals.max()}\")\n",
    "\n",
    "    # Normalize and scale to full 16-bit range\n",
    "    modified_signals = final_modified_scale_signals_to_bit_depth(modified_signals, 16)\n",
    "    print(f\"Scaled range: {modified_signals.min()} to {modified_signals.max()}\")\n",
    "\n",
    "    return modified_signals\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    bit_depth = 16        # Bit depth of the signals\n",
    "    num_signals = 8      # Number of signals\n",
    "    fs = 500              # Sampling rate in Hz\n",
    "    duration = 3600          # Duration in seconds\n",
    "    length = fs * duration\n",
    "\n",
    "    # Global variables for amplitude range\n",
    "    min_volt = 1\n",
    "    max_volt = 8  \n",
    "\n",
    "    # Calculate the length of the signals\n",
    "    length = fs * duration\n",
    "\n",
    "    # Generate and transform the ECoG-like signals\n",
    "    transformed_signals = generate_transformed_signals(length, num_signals, transformations)\n",
    "\n",
    "    # Convert transformed_signals to a NumPy array to access the shape attribute\n",
    "    transformed_signals_array = np.array(transformed_signals)\n",
    "\n",
    "    # Check the shape and a sample of the generated signals\n",
    "    print(f\"Shape of generated ECoG-like signals: {transformed_signals_array.shape}\")\n",
    "    for i in range(8):\n",
    "        print(f\"Sample of signal {i + 1}: {transformed_signals_array[i][:50]}\")\n",
    "\n",
    "    # Check the shape and a sample of the generated signals\n",
    "    print(f\"Shape of generated ECoG-like signals: {transformed_signals_array.shape}\")\n",
    "    print(f\"Sample of first signal: {transformed_signals_array[0][:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaa1ec7-fb5e-4157-b77e-0a0ee3b9c6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from neuroplatform import StimParam, IntanSoftware, Trigger, Experiment\n",
    "\n",
    "# Set the experiment token and initialize the experiment\n",
    "token = \"XSALK6J9C4\"\n",
    "exp = Experiment(token)\n",
    "print(f'Electrodes: {32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63}')  # Electrodes that you can use\n",
    "\n",
    "num_read_elecs = 32\n",
    "num_stim_elecs = 8  # Number of neural stimulators\n",
    "\n",
    "# Define the stimulation pattern with manual chunks\n",
    "stimulation_pattern = [\n",
    "    60,    # 1 minute no stim\n",
    "    300,   # 5 minutes stim\n",
    "    60,    # 1 minute no stim\n",
    "    600,   # 10 minutes stim\n",
    "    60,    # 1 minute no stim\n",
    "    900,   # 15 minutes stim\n",
    "    60,    # 1 minute no stim\n",
    "    1200   # 20 minutes stim\n",
    "    60     # 1 minute no stim\n",
    "]\n",
    "\n",
    "# Function to stimulate electrodes with transformed signals\n",
    "def stimulate_electrodes(intan, trigger_gens, stim_params, transformed_signals, start_idx, duration):\n",
    "    \"\"\"\n",
    "    Stimulate electrodes with transformed signals.\n",
    "    \n",
    "    Parameters:\n",
    "    - intan: IntanSoftware instance to interact with the hardware.\n",
    "    - trigger_gens: List of Trigger instances for sending trigger signals.\n",
    "    - stim_params: List of StimParam objects configured for stimulation.\n",
    "    - transformed_signals: Array of signals for direct stimulation.\n",
    "    - start_idx: Starting index for the stimulation segment.\n",
    "    - duration: Duration of the stimulation segment.\n",
    "    \"\"\"\n",
    "    end_idx = start_idx + duration * intan.sampling_rate  # Calculate end index based on duration and sampling rate\n",
    "    segment = transformed_signals[:, start_idx:end_idx]  # Extract the segment of the signals for the given duration\n",
    "\n",
    "    for i, trigger_gen in enumerate(trigger_gens):\n",
    "        for j in range(len(segment[i])):\n",
    "            # Configure trigger for the current electrode\n",
    "            trigger_key = stim_params[i].trigger_key\n",
    "            trigger0 = np.zeros(16, dtype=np.uint8)  # Assuming 16 is correct for your setup\n",
    "            trigger0[trigger_key] = 1\n",
    "\n",
    "            # Send the trigger signal to the electrode\n",
    "            intan.send_stimulus(trigger_gen, stim_params[i].index, segment[i, j])\n",
    "            time.sleep(1 / intan.sampling_rate)  # Wait for the duration of one sample\n",
    "\n",
    "            # Reset trigger for the next electrode\n",
    "            trigger0[trigger_key] = 0\n",
    "            trigger_gen.send(trigger0)\n",
    "\n",
    "intan = IntanSoftware()\n",
    "trigger_gens = [Trigger() for _ in range(num_stim_elecs)]  # One trigger generator per stimulator\n",
    "\n",
    "stim_params = []  # Initialize an empty list for stimulation parameters\n",
    "\n",
    "for i in range(num_stim_elecs):\n",
    "    stim_param = StimParam()\n",
    "    stim_param.index = i + 32  # Assuming electrodes 32-39 are used for stimulation\n",
    "    stim_param.trigger_key = i  # Mapping each electrode to a trigger key, one per stimulator\n",
    "    stim_params.append(stim_param)\n",
    "\n",
    "try:\n",
    "    if exp.start():\n",
    "        intan.impedance()  # Measure impedance\n",
    "        \n",
    "        # Send stimulation parameters to the Intan hardware\n",
    "        intan.send_stimparam(stim_params)\n",
    "\n",
    "        # Start raw recording on channels selected\n",
    "        raw_channels = np.array(range(num_read_elecs), dtype=np.int32) \n",
    "        intan.start_raw_recording(raw_channels)\n",
    "        \n",
    "        # Start recording stimulation data\n",
    "        intan.start_stimulation_recording()\n",
    "\n",
    "        start_idx = 0  # Initialize starting index for stimulation\n",
    "        total_stim_data_length = 45 * 60 * intan.sampling_rate  # Total length of the stimulation data in samples\n",
    "\n",
    "        for duration in stimulation_pattern:\n",
    "            if duration > 0:\n",
    "                if duration % 60 == 0:\n",
    "                    # Stimulate for the specified duration\n",
    "                    print(f\"Stimulation for {duration // 60} minute(s)...\")\n",
    "                    stimulate_electrodes(intan, trigger_gens, stim_params, transformed_signals, start_idx, duration)\n",
    "                    start_idx += duration * intan.sampling_rate  # Increment start index by the duration of samples\n",
    "                    if start_idx >= total_stim_data_length:\n",
    "                        print(\"End of stimulation data reached. Wrapping around to start.\")\n",
    "                        start_idx = 0  # Wrap around if the end of the data is reached\n",
    "                else:\n",
    "                    # No stim for the specified duration\n",
    "                    print(f\"No stimulation for {duration} seconds...\")\n",
    "                    time.sleep(duration)\n",
    "\n",
    "finally:\n",
    "    for trigger_gen in trigger_gens:\n",
    "        trigger_gen.close()\n",
    "    intan.stop_stimulation_recording()\n",
    "    intan.close()\n",
    "    exp.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
