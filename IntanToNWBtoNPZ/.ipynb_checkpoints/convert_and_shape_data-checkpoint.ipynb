{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c22c1249-44b2-4afb-8685-61ea9f2b8ad5",
   "metadata": {},
   "source": [
    "# Print contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c99f9f7d-f8ba-4c4a-b37d-7cf27f64f0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition Groups:\n",
      " - ElectricalSeries\n",
      "\n",
      "Stimulus Groups:\n",
      " - TimeSeries_amp_settle\n",
      " - TimeSeries_charge_recovery\n",
      " - TimeSeries_compliance_limit\n",
      " - TimeSeries_stimulation\n"
     ]
    }
   ],
   "source": [
    "from pynwb import NWBHDF5IO\n",
    "\n",
    "def list_nwb_components(nwb_file_path):\n",
    "    with NWBHDF5IO(nwb_file_path, 'r') as io:\n",
    "        nwbfile = io.read()\n",
    "\n",
    "        print(\"Acquisition Groups:\")\n",
    "        acquisition = nwbfile.acquisition\n",
    "        for name in acquisition:\n",
    "            print(f\" - {name}\")\n",
    "\n",
    "        if hasattr(nwbfile, 'stimulus'):\n",
    "            print(\"\\nStimulus Groups:\")\n",
    "            stimulus = nwbfile.stimulus\n",
    "            for name in stimulus:\n",
    "                print(f\" - {name}\")\n",
    "\n",
    "# Path to your .nwb file\n",
    "nwb_file_path = 'data1.nwb'\n",
    "\n",
    "# List all components\n",
    "list_nwb_components(nwb_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a300dca3-9b37-461b-ad1a-9014a9a17fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition Groups:\n",
      "\n",
      "ElectricalSeries:\n",
      " - Comments: voltage data recorded from the amplifiers of an Intan Technologies chip\n",
      " - Description: voltage data recorded from the amplifiers of an Intan Technologies chip\n",
      " - Unit: volts\n",
      " - Data shape: (65280, 64)\n",
      " - Timestamps shape: (65280,)\n",
      "\n",
      "Stimulus Groups:\n",
      "\n",
      "TimeSeries_amp_settle:\n",
      " - Comments: amplifier settle activity of an Intan Technologies chip\n",
      " - Description: amplifier settle activity of an Intan Technologies chip\n",
      " - Unit: digital event\n",
      " - Data shape: (65280, 64)\n",
      " - Timestamps shape: (65280,)\n",
      "\n",
      "TimeSeries_charge_recovery:\n",
      " - Comments: charge recovery activity of an Intan Technologies chip\n",
      " - Description: charge recovery activity of an Intan Technologies chip\n",
      " - Unit: digital event\n",
      " - Data shape: (65280, 64)\n",
      " - Timestamps shape: (65280,)\n",
      "\n",
      "TimeSeries_compliance_limit:\n",
      " - Comments: compliance limit activity of an Intan Technologies chip\n",
      " - Description: compliance limit activity of an Intan Technologies chip\n",
      " - Unit: digital event\n",
      " - Data shape: (65280, 64)\n",
      " - Timestamps shape: (65280,)\n",
      "\n",
      "TimeSeries_stimulation:\n",
      " - Comments: current stimulation activity of an Intan Technologies chip\n",
      " - Description: current stimulation activity of an Intan Technologies chip\n",
      " - Unit: amps\n",
      " - Data shape: (65280, 64)\n",
      " - Timestamps shape: (65280,)\n"
     ]
    }
   ],
   "source": [
    "from pynwb import NWBHDF5IO\n",
    "\n",
    "# Replace with the path to your .nwb file\n",
    "nwb_file_path = 'data1.nwb'\n",
    "\n",
    "# Function to print details of a TimeSeries object\n",
    "def print_timeseries_details(name, timeseries):\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\" - Comments: {timeseries.comments}\")\n",
    "    print(f\" - Description: {timeseries.description}\")\n",
    "    print(f\" - Unit: {timeseries.unit}\")\n",
    "    print(f\" - Data shape: {timeseries.data.shape}\")\n",
    "    print(f\" - Timestamps shape: {timeseries.timestamps.shape if timeseries.timestamps else 'No timestamps'}\")\n",
    "\n",
    "# Open the .nwb file using PyNWB\n",
    "with NWBHDF5IO(nwb_file_path, 'r') as io:\n",
    "    nwbfile = io.read()\n",
    "\n",
    "    # Access and print details of the acquisition group\n",
    "    print(\"Acquisition Groups:\")\n",
    "    acquisition = nwbfile.acquisition\n",
    "    for name, timeseries in acquisition.items():\n",
    "        print_timeseries_details(name, timeseries)\n",
    "\n",
    "    # Access and print details of the stimulus group\n",
    "    if hasattr(nwbfile, 'stimulus'):\n",
    "        print(\"\\nStimulus Groups:\")\n",
    "        for name, timeseries in nwbfile.stimulus.items():\n",
    "            print_timeseries_details(name, timeseries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e12254-d214-4c48-8ade-fcdf0ecba78e",
   "metadata": {},
   "source": [
    "### Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77fcda67-a40f-421e-be46-11d10179a727",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElectricalSeries dataset shape: (65280, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "from pynwb import NWBHDF5IO\n",
    "import numpy as np\n",
    "\n",
    "def extract_electrical_series_data(nwb_file_path):\n",
    "    with NWBHDF5IO(nwb_file_path, 'r') as io:\n",
    "        nwbfile = io.read()\n",
    "\n",
    "        seq_len = 65280  # Number of time points\n",
    "        electrodes = 64  # Total number of electrodes (8x8 grid)\n",
    "\n",
    "        # Extract data from the ElectricalSeries component\n",
    "        electrical_series = nwbfile.acquisition.get('ElectricalSeries')\n",
    "        if electrical_series is None:\n",
    "            raise ValueError(\"ElectricalSeries component not found.\")\n",
    "\n",
    "        data = np.array(electrical_series.data[:])\n",
    "        \n",
    "        # Check the shape of the data\n",
    "        if data.ndim != 2 or data.shape[1] != electrodes:\n",
    "            raise ValueError(\"Incorrect data shape in ElectricalSeries\")\n",
    "\n",
    "        # Reshape the data to (seq_len, 8, 8)\n",
    "        reshaped_data = data.reshape((seq_len, 8, 8))\n",
    "        return reshaped_data\n",
    "\n",
    "# Path to your .nwb file\n",
    "nwb_file_path = 'data1.nwb'\n",
    "\n",
    "# Extract and reshape ElectricalSeries data\n",
    "electrical_series_data = extract_electrical_series_data(nwb_file_path)\n",
    "print(\"ElectricalSeries dataset shape:\", electrical_series_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2121340d-dac4-4e19-b91a-d7310ee5d802",
   "metadata": {},
   "source": [
    "### Print first 10 rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1edb02b-372e-42af-ba4e-ae13b5fc202e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows of ElectricalSeries:\n",
      "Timepoint 1:\n",
      "[[ 2.53500002e-06  7.21500010e-06 -3.89999997e-07  3.90000014e-06\n",
      "   4.29000011e-06 -7.01999988e-06 -1.13099995e-05  2.73000001e-06]\n",
      " [ 3.50999994e-06  1.40399998e-05 -7.01999988e-06  1.36500000e-06\n",
      "   3.11999997e-06 -2.14500005e-06  1.95000007e-06  9.75000034e-07]\n",
      " [ 2.53500002e-06  7.21500010e-06 -3.89999997e-07  3.90000014e-06\n",
      "   4.29000011e-06 -7.01999988e-06 -1.13099995e-05  2.73000001e-06]\n",
      " [ 3.50999994e-06  1.40399998e-05 -7.01999988e-06  1.36500000e-06\n",
      "   3.11999997e-06 -2.14500005e-06  1.95000007e-06  9.75000034e-07]\n",
      " [ 2.53500002e-06  7.21500010e-06 -3.89999997e-07  3.90000014e-06\n",
      "   4.29000011e-06 -7.01999988e-06 -1.13099995e-05  2.73000001e-06]\n",
      " [ 3.50999994e-06  1.40399998e-05 -7.01999988e-06  1.36500000e-06\n",
      "   3.11999997e-06 -2.14500005e-06  1.95000007e-06  9.75000034e-07]\n",
      " [ 2.53500002e-06  7.21500010e-06 -3.89999997e-07  3.90000014e-06\n",
      "   4.29000011e-06 -7.01999988e-06 -1.13099995e-05  2.73000001e-06]\n",
      " [ 3.50999994e-06  1.40399998e-05 -7.01999988e-06  1.36500000e-06\n",
      "   3.11999997e-06 -2.14500005e-06  1.95000007e-06  9.75000034e-07]]\n",
      "Timepoint 2:\n",
      "[[-5.0700000e-06  5.4600000e-06 -2.9250000e-06 -5.6549998e-06\n",
      "   4.6800001e-06 -9.9449999e-06 -9.7500003e-07  4.6800001e-06]\n",
      " [-9.9449999e-06  2.7300000e-06  5.8500001e-07  2.7300000e-06\n",
      "  -5.2649998e-06  1.2480000e-05 -1.5600000e-06  8.3850000e-06]\n",
      " [-5.0700000e-06  5.4600000e-06 -2.9250000e-06 -5.6549998e-06\n",
      "   4.6800001e-06 -9.9449999e-06 -9.7500003e-07  4.6800001e-06]\n",
      " [-9.9449999e-06  2.7300000e-06  5.8500001e-07  2.7300000e-06\n",
      "  -5.2649998e-06  1.2480000e-05 -1.5600000e-06  8.3850000e-06]\n",
      " [-5.0700000e-06  5.4600000e-06 -2.9250000e-06 -5.6549998e-06\n",
      "   4.6800001e-06 -9.9449999e-06 -9.7500003e-07  4.6800001e-06]\n",
      " [-9.9449999e-06  2.7300000e-06  5.8500001e-07  2.7300000e-06\n",
      "  -5.2649998e-06  1.2480000e-05 -1.5600000e-06  8.3850000e-06]\n",
      " [-5.0700000e-06  5.4600000e-06 -2.9250000e-06 -5.6549998e-06\n",
      "   4.6800001e-06 -9.9449999e-06 -9.7500003e-07  4.6800001e-06]\n",
      " [-9.9449999e-06  2.7300000e-06  5.8500001e-07  2.7300000e-06\n",
      "  -5.2649998e-06  1.2480000e-05 -1.5600000e-06  8.3850000e-06]]\n",
      "Timepoint 3:\n",
      "[[ 1.5600000e-06  5.6549998e-06  1.1505000e-05 -3.3150000e-06\n",
      "   2.1450001e-06  5.8500000e-06  5.4600000e-06 -2.9250000e-06]\n",
      " [-3.7049999e-06  2.7300000e-06 -5.8500001e-07 -2.7300000e-06\n",
      "  -3.9000001e-06  8.1899998e-06 -1.7550000e-06  9.5550004e-06]\n",
      " [ 1.5600000e-06  5.6549998e-06  1.1505000e-05 -3.3150000e-06\n",
      "   2.1450001e-06  5.8500000e-06  5.4600000e-06 -2.9250000e-06]\n",
      " [-3.7049999e-06  2.7300000e-06 -5.8500001e-07 -2.7300000e-06\n",
      "  -3.9000001e-06  8.1899998e-06 -1.7550000e-06  9.5550004e-06]\n",
      " [ 1.5600000e-06  5.6549998e-06  1.1505000e-05 -3.3150000e-06\n",
      "   2.1450001e-06  5.8500000e-06  5.4600000e-06 -2.9250000e-06]\n",
      " [-3.7049999e-06  2.7300000e-06 -5.8500001e-07 -2.7300000e-06\n",
      "  -3.9000001e-06  8.1899998e-06 -1.7550000e-06  9.5550004e-06]\n",
      " [ 1.5600000e-06  5.6549998e-06  1.1505000e-05 -3.3150000e-06\n",
      "   2.1450001e-06  5.8500000e-06  5.4600000e-06 -2.9250000e-06]\n",
      " [-3.7049999e-06  2.7300000e-06 -5.8500001e-07 -2.7300000e-06\n",
      "  -3.9000001e-06  8.1899998e-06 -1.7550000e-06  9.5550004e-06]]\n",
      "Timepoint 4:\n",
      "[[ 5.84999998e-06 -1.75499997e-06  4.48499986e-06  1.94999998e-07\n",
      "  -3.31499996e-06  1.17000002e-06 -3.70499993e-06  1.36500000e-06]\n",
      " [ 2.53500002e-06 -9.75000034e-07 -1.46249995e-05  1.94999998e-07\n",
      "   2.73000001e-06  7.40999985e-06 -9.16499994e-06 -2.53500002e-06]\n",
      " [ 5.84999998e-06 -1.75499997e-06  4.48499986e-06  1.94999998e-07\n",
      "  -3.31499996e-06  1.17000002e-06 -3.70499993e-06  1.36500000e-06]\n",
      " [ 2.53500002e-06 -9.75000034e-07 -1.46249995e-05  1.94999998e-07\n",
      "   2.73000001e-06  7.40999985e-06 -9.16499994e-06 -2.53500002e-06]\n",
      " [ 5.84999998e-06 -1.75499997e-06  4.48499986e-06  1.94999998e-07\n",
      "  -3.31499996e-06  1.17000002e-06 -3.70499993e-06  1.36500000e-06]\n",
      " [ 2.53500002e-06 -9.75000034e-07 -1.46249995e-05  1.94999998e-07\n",
      "   2.73000001e-06  7.40999985e-06 -9.16499994e-06 -2.53500002e-06]\n",
      " [ 5.84999998e-06 -1.75499997e-06  4.48499986e-06  1.94999998e-07\n",
      "  -3.31499996e-06  1.17000002e-06 -3.70499993e-06  1.36500000e-06]\n",
      " [ 2.53500002e-06 -9.75000034e-07 -1.46249995e-05  1.94999998e-07\n",
      "   2.73000001e-06  7.40999985e-06 -9.16499994e-06 -2.53500002e-06]]\n",
      "Timepoint 5:\n",
      "[[-8.970e-06  2.145e-06  5.850e-06 -2.925e-06  6.240e-06 -6.630e-06\n",
      "  -2.925e-06 -7.995e-06]\n",
      " [ 2.925e-06  8.970e-06 -1.950e-07  3.705e-06  1.950e-06 -4.485e-06\n",
      "  -2.730e-06 -6.825e-06]\n",
      " [-8.970e-06  2.145e-06  5.850e-06 -2.925e-06  6.240e-06 -6.630e-06\n",
      "  -2.925e-06 -7.995e-06]\n",
      " [ 2.925e-06  8.970e-06 -1.950e-07  3.705e-06  1.950e-06 -4.485e-06\n",
      "  -2.730e-06 -6.825e-06]\n",
      " [-8.970e-06  2.145e-06  5.850e-06 -2.925e-06  6.240e-06 -6.630e-06\n",
      "  -2.925e-06 -7.995e-06]\n",
      " [ 2.925e-06  8.970e-06 -1.950e-07  3.705e-06  1.950e-06 -4.485e-06\n",
      "  -2.730e-06 -6.825e-06]\n",
      " [-8.970e-06  2.145e-06  5.850e-06 -2.925e-06  6.240e-06 -6.630e-06\n",
      "  -2.925e-06 -7.995e-06]\n",
      " [ 2.925e-06  8.970e-06 -1.950e-07  3.705e-06  1.950e-06 -4.485e-06\n",
      "  -2.730e-06 -6.825e-06]]\n",
      "Timepoint 6:\n",
      "[[-2.535e-06 -6.435e-06 -1.443e-05  7.800e-07  9.750e-07  3.510e-06\n",
      "  -7.410e-06  4.875e-06]\n",
      " [ 7.215e-06  6.240e-06  5.850e-06 -7.995e-06 -1.950e-07  7.605e-06\n",
      "  -1.170e-06 -1.755e-06]\n",
      " [-2.535e-06 -6.435e-06 -1.443e-05  7.800e-07  9.750e-07  3.510e-06\n",
      "  -7.410e-06  4.875e-06]\n",
      " [ 7.215e-06  6.240e-06  5.850e-06 -7.995e-06 -1.950e-07  7.605e-06\n",
      "  -1.170e-06 -1.755e-06]\n",
      " [-2.535e-06 -6.435e-06 -1.443e-05  7.800e-07  9.750e-07  3.510e-06\n",
      "  -7.410e-06  4.875e-06]\n",
      " [ 7.215e-06  6.240e-06  5.850e-06 -7.995e-06 -1.950e-07  7.605e-06\n",
      "  -1.170e-06 -1.755e-06]\n",
      " [-2.535e-06 -6.435e-06 -1.443e-05  7.800e-07  9.750e-07  3.510e-06\n",
      "  -7.410e-06  4.875e-06]\n",
      " [ 7.215e-06  6.240e-06  5.850e-06 -7.995e-06 -1.950e-07  7.605e-06\n",
      "  -1.170e-06 -1.755e-06]]\n",
      "Timepoint 7:\n",
      "[[-4.680e-06  5.460e-06  2.340e-06  2.925e-06  4.875e-06  3.900e-06\n",
      "  -5.850e-06 -1.755e-06]\n",
      " [ 1.560e-06 -9.750e-07  8.580e-06  4.095e-06 -1.950e-06 -7.995e-06\n",
      "  -4.095e-06 -3.900e-06]\n",
      " [-4.680e-06  5.460e-06  2.340e-06  2.925e-06  4.875e-06  3.900e-06\n",
      "  -5.850e-06 -1.755e-06]\n",
      " [ 1.560e-06 -9.750e-07  8.580e-06  4.095e-06 -1.950e-06 -7.995e-06\n",
      "  -4.095e-06 -3.900e-06]\n",
      " [-4.680e-06  5.460e-06  2.340e-06  2.925e-06  4.875e-06  3.900e-06\n",
      "  -5.850e-06 -1.755e-06]\n",
      " [ 1.560e-06 -9.750e-07  8.580e-06  4.095e-06 -1.950e-06 -7.995e-06\n",
      "  -4.095e-06 -3.900e-06]\n",
      " [-4.680e-06  5.460e-06  2.340e-06  2.925e-06  4.875e-06  3.900e-06\n",
      "  -5.850e-06 -1.755e-06]\n",
      " [ 1.560e-06 -9.750e-07  8.580e-06  4.095e-06 -1.950e-06 -7.995e-06\n",
      "  -4.095e-06 -3.900e-06]]\n",
      "Timepoint 8:\n",
      "[[ 0.0000000e+00  0.0000000e+00 -4.2900001e-06  7.9949996e-06\n",
      "   2.5350000e-06 -8.5800002e-06  9.7500003e-07  4.4849999e-06]\n",
      " [ 7.4099999e-06 -7.2150001e-06 -8.7749995e-06 -2.5350000e-06\n",
      "  -9.9449999e-06  9.7500003e-07  1.9500001e-06 -8.7749995e-06]\n",
      " [ 0.0000000e+00  0.0000000e+00 -4.2900001e-06  7.9949996e-06\n",
      "   2.5350000e-06 -8.5800002e-06  9.7500003e-07  4.4849999e-06]\n",
      " [ 7.4099999e-06 -7.2150001e-06 -8.7749995e-06 -2.5350000e-06\n",
      "  -9.9449999e-06  9.7500003e-07  1.9500001e-06 -8.7749995e-06]\n",
      " [ 0.0000000e+00  0.0000000e+00 -4.2900001e-06  7.9949996e-06\n",
      "   2.5350000e-06 -8.5800002e-06  9.7500003e-07  4.4849999e-06]\n",
      " [ 7.4099999e-06 -7.2150001e-06 -8.7749995e-06 -2.5350000e-06\n",
      "  -9.9449999e-06  9.7500003e-07  1.9500001e-06 -8.7749995e-06]\n",
      " [ 0.0000000e+00  0.0000000e+00 -4.2900001e-06  7.9949996e-06\n",
      "   2.5350000e-06 -8.5800002e-06  9.7500003e-07  4.4849999e-06]\n",
      " [ 7.4099999e-06 -7.2150001e-06 -8.7749995e-06 -2.5350000e-06\n",
      "  -9.9449999e-06  9.7500003e-07  1.9500001e-06 -8.7749995e-06]]\n",
      "Timepoint 9:\n",
      "[[ 2.9250000e-06  2.1450001e-06  4.8749998e-06 -2.7300000e-06\n",
      "  -1.9500000e-07  5.4600000e-06 -7.7999999e-07 -6.2399999e-06]\n",
      " [ 7.4099999e-06 -9.5550004e-06  6.6299999e-06  1.3650000e-06\n",
      "   3.9000000e-07  7.7999999e-07  5.6549998e-06  1.9500000e-07]\n",
      " [ 2.9250000e-06  2.1450001e-06  4.8749998e-06 -2.7300000e-06\n",
      "  -1.9500000e-07  5.4600000e-06 -7.7999999e-07 -6.2399999e-06]\n",
      " [ 7.4099999e-06 -9.5550004e-06  6.6299999e-06  1.3650000e-06\n",
      "   3.9000000e-07  7.7999999e-07  5.6549998e-06  1.9500000e-07]\n",
      " [ 2.9250000e-06  2.1450001e-06  4.8749998e-06 -2.7300000e-06\n",
      "  -1.9500000e-07  5.4600000e-06 -7.7999999e-07 -6.2399999e-06]\n",
      " [ 7.4099999e-06 -9.5550004e-06  6.6299999e-06  1.3650000e-06\n",
      "   3.9000000e-07  7.7999999e-07  5.6549998e-06  1.9500000e-07]\n",
      " [ 2.9250000e-06  2.1450001e-06  4.8749998e-06 -2.7300000e-06\n",
      "  -1.9500000e-07  5.4600000e-06 -7.7999999e-07 -6.2399999e-06]\n",
      " [ 7.4099999e-06 -9.5550004e-06  6.6299999e-06  1.3650000e-06\n",
      "   3.9000000e-07  7.7999999e-07  5.6549998e-06  1.9500000e-07]]\n",
      "Timepoint 10:\n",
      "[[-1.170e-06 -7.605e-06  5.850e-06  7.800e-07 -3.900e-07  7.800e-07\n",
      "   5.460e-06  1.365e-06]\n",
      " [ 2.535e-06 -8.580e-06 -2.535e-06  1.092e-05  7.410e-06  3.900e-06\n",
      "  -1.170e-06  7.800e-07]\n",
      " [-1.170e-06 -7.605e-06  5.850e-06  7.800e-07 -3.900e-07  7.800e-07\n",
      "   5.460e-06  1.365e-06]\n",
      " [ 2.535e-06 -8.580e-06 -2.535e-06  1.092e-05  7.410e-06  3.900e-06\n",
      "  -1.170e-06  7.800e-07]\n",
      " [-1.170e-06 -7.605e-06  5.850e-06  7.800e-07 -3.900e-07  7.800e-07\n",
      "   5.460e-06  1.365e-06]\n",
      " [ 2.535e-06 -8.580e-06 -2.535e-06  1.092e-05  7.410e-06  3.900e-06\n",
      "  -1.170e-06  7.800e-07]\n",
      " [-1.170e-06 -7.605e-06  5.850e-06  7.800e-07 -3.900e-07  7.800e-07\n",
      "   5.460e-06  1.365e-06]\n",
      " [ 2.535e-06 -8.580e-06 -2.535e-06  1.092e-05  7.410e-06  3.900e-06\n",
      "  -1.170e-06  7.800e-07]]\n"
     ]
    }
   ],
   "source": [
    "from pynwb import NWBHDF5IO\n",
    "import numpy as np\n",
    "\n",
    "def print_first_10_rows_electrical_series(nwb_file_path):\n",
    "    with NWBHDF5IO(nwb_file_path, 'r') as io:\n",
    "        nwbfile = io.read()\n",
    "\n",
    "        # Access ElectricalSeries data\n",
    "        electrical_series = nwbfile.acquisition.get('ElectricalSeries')\n",
    "        if electrical_series is None:\n",
    "            print(\"ElectricalSeries component not found.\")\n",
    "            return\n",
    "\n",
    "        # Extract and reshape data\n",
    "        data = np.array(electrical_series.data[:])\n",
    "        seq_len, electrodes = data.shape\n",
    "        reshaped_data = data.reshape((seq_len, 8, 8))\n",
    "\n",
    "        # Print the first 10 rows\n",
    "        print(\"\\nFirst 10 rows of ElectricalSeries:\")\n",
    "        for row in range(10):\n",
    "            print(f\"Timepoint {row + 1}:\\n{reshaped_data[row, :, :]}\")\n",
    "\n",
    "# Path to your .nwb file\n",
    "nwb_file_path = 'data1.nwb'  # Replace with the correct file path\n",
    "\n",
    "# Print the first 10 rows of ElectricalSeries\n",
    "print_first_10_rows_electrical_series(nwb_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00df2914-2eaa-425b-87cd-581e8f922937",
   "metadata": {},
   "source": [
    "### Check for non zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25db32f6-c942-4bef-854a-4dce3ce0ccfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElectricalSeries:\n",
      " - Total non-zero elements: 4173640\n",
      " - Total elements: 4177920\n",
      " - Percentage of non-zero elements: 99.90%\n",
      "\n",
      "TimeSeries_amp_settle:\n",
      " - Total non-zero elements: 0\n",
      " - Total elements: 4177920\n",
      " - Percentage of non-zero elements: 0.00%\n",
      "\n",
      "TimeSeries_charge_recovery:\n",
      " - Total non-zero elements: 0\n",
      " - Total elements: 4177920\n",
      " - Percentage of non-zero elements: 0.00%\n",
      "\n",
      "TimeSeries_compliance_limit:\n",
      " - Total non-zero elements: 0\n",
      " - Total elements: 4177920\n",
      " - Percentage of non-zero elements: 0.00%\n",
      "\n",
      "TimeSeries_stimulation:\n",
      " - Total non-zero elements: 0\n",
      " - Total elements: 4177920\n",
      " - Percentage of non-zero elements: 0.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def check_for_nonzero_values(datasets):\n",
    "    for component, data in datasets.items():\n",
    "        non_zero_count = np.count_nonzero(data)\n",
    "        total_elements = data.size\n",
    "        print(f\"{component}:\")\n",
    "        print(f\" - Total non-zero elements: {non_zero_count}\")\n",
    "        print(f\" - Total elements: {total_elements}\")\n",
    "        print(f\" - Percentage of non-zero elements: {100 * non_zero_count / total_elements:.2f}%\\n\")\n",
    "\n",
    "# Call the function to check for non-zero values\n",
    "check_for_nonzero_values(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c613e6-3468-4fc3-8247-362154d1f52a",
   "metadata": {},
   "source": [
    "# Next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13a1ee69-6162-47b6-b0a2-b25d02f65c8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 125\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Replace 'your/directory/path' with the actual path where your .npz files are located\u001b[39;00m\n\u001b[1;32m    124\u001b[0m directory_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/vincent/AAA_projects/UnlimitedResearchCooperative/Synthetic_Intelligence_Labs/human-cortical-organoid-signal-analysis/IntanToNWBtoNPZ/ElectricalSeries.npz\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 125\u001b[0m \u001b[43mread_in_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 117\u001b[0m, in \u001b[0;36mread_in_data\u001b[0;34m(dirPath)\u001b[0m\n\u001b[1;32m    115\u001b[0m offset_trigger_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m    116\u001b[0m listFiles \u001b[38;5;241m=\u001b[39m getListFiles(dirPath)\n\u001b[0;32m--> 117\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirPath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset_trigger_ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlistFiles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconverting spatial position\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    119\u001b[0m dataset \u001b[38;5;241m=\u001b[39m convertFlatRaw4x3x4x3(dataset)\n",
      "Cell \u001b[0;32mIn[12], line 34\u001b[0m, in \u001b[0;36mcreate_array\u001b[0;34m(dirPath, offset, listFiles)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# number of pre and post stimulation files \u001b[39;00m\n\u001b[1;32m     33\u001b[0m nbr_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(listFiles)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m total_nbr_stim_per_file,nbr_stim_per_electrode,nbr_electrodes,nbr_neurospheres,seq_len \u001b[38;5;241m=\u001b[39m \u001b[43mrecording_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirPath\u001b[49m\u001b[43m,\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# create two arrays of size (N,8,8,3001), each one corresponding to one of the class\u001b[39;00m\n\u001b[1;32m     37\u001b[0m raw1_reshaped \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((total_nbr_stim_per_file\u001b[38;5;241m*\u001b[39mnbr_files,nbr_electrodes,nbr_electrodes,seq_len\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "Cell \u001b[0;32mIn[12], line 88\u001b[0m, in \u001b[0;36mrecording_parameters\u001b[0;34m(dirPath, offset)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m#file_data = load_raw_data(f'{dirPath}/exp_{0}_0_{offset}.npz')\u001b[39;00m\n\u001b[1;32m     87\u001b[0m file_data \u001b[38;5;241m=\u001b[39m load_raw_data(dirPath)\n\u001b[0;32m---> 88\u001b[0m nbr_stim_per_electrode \u001b[38;5;241m=\u001b[39m \u001b[43mfile_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     89\u001b[0m nbr_electrodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m     90\u001b[0m nbr_neurospheres \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(file_data[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m8\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "\n",
    "#Reads In Data to (N, 1, 8, 8, S) array\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def load_raw_data(filename: str):\n",
    "    # Load the npz file\n",
    "    loaded = np.load(filename)\n",
    "    \n",
    "    # Extract the data for each timepoint and store it in a list\n",
    "    data = []\n",
    "    for i in range(4177920):  # Adjust this number based on the actual number of timepoints in your data\n",
    "        timepoint_key = f'timepoint_{i}'  # Construct the key name\n",
    "        if timepoint_key in loaded:\n",
    "            timepoint_data = loaded[timepoint_key]\n",
    "            data.append(timepoint_data)\n",
    "        else:\n",
    "            break  # Exit the loop if the key is not found\n",
    "    return np.array(data)\n",
    "\n",
    "\n",
    "\n",
    "def create_array(dirPath:str, offset:int,listFiles:list):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "    dirPath: [str] path to directory\n",
    "    offset: [int] time delay before before recording after a stimulus\n",
    "    OUTPUT: \n",
    "    dataset: [np.array] an array of shape (N,8,8,3001) containing the data\n",
    "    \"\"\"\n",
    "    # number of pre and post stimulation files \n",
    "    nbr_files = int(len(listFiles)/2)\n",
    "    total_nbr_stim_per_file,nbr_stim_per_electrode,nbr_electrodes,nbr_neurospheres,seq_len = recording_parameters(dirPath,offset)\n",
    "\n",
    "    # create two arrays of size (N,8,8,3001), each one corresponding to one of the class\n",
    "    raw1_reshaped = np.zeros((total_nbr_stim_per_file*nbr_files,nbr_electrodes,nbr_electrodes,seq_len+1))\n",
    "    raw2_reshaped = np.zeros((total_nbr_stim_per_file*nbr_files,nbr_electrodes,nbr_electrodes,seq_len+1))\n",
    "\n",
    "    # fill these arrays with corresponding values from files\n",
    "    for start_exp_index in range(nbr_files):\n",
    "        print(f'experiment number:{start_exp_index}')\n",
    "        raw1 = load_raw_data(f'{dirPath}/exp_{start_exp_index}_0_{offset}.npz')\n",
    "        raw2 = load_raw_data(f'{dirPath}/exp_{start_exp_index}_1_{offset}.npz')\n",
    "\n",
    "        # reshape (80,8,8,3000)\n",
    "        raw1_one_file = np.zeros((total_nbr_stim_per_file,nbr_electrodes,nbr_electrodes,raw1[0].shape[2]))\n",
    "        raw2_one_file = np.zeros((total_nbr_stim_per_file,nbr_electrodes,nbr_electrodes,raw2[0].shape[2]))\n",
    "\n",
    "        # iterate through electrode stimulated and neurospheres\n",
    "        for electrode in range(nbr_electrodes):\n",
    "            #nbr_neurospheres = int(raw1[electrode].shape[1]/8)\n",
    "            # N: number of reptition of the stimulus\n",
    "            N = raw1[1].shape[0]\n",
    "            for i in range(nbr_neurospheres):\n",
    "                j = nbr_electrodes*i\n",
    "                raw1_one_file[N*i:N*(i+1),electrode] = raw1[electrode][:N,j:j+nbr_electrodes]\n",
    "                raw2_one_file[N*i:N*(i+1),electrode] = raw2[electrode][:N,j:j+nbr_electrodes]\n",
    "        raw1_reshaped[total_nbr_stim_per_file*start_exp_index:total_nbr_stim_per_file*(start_exp_index+1),:,:,:seq_len] = raw1_one_file\n",
    "        raw2_reshaped[total_nbr_stim_per_file*start_exp_index:total_nbr_stim_per_file*(start_exp_index+1),:,:,:seq_len] = raw2_one_file\n",
    "\n",
    "    # append label\n",
    "    print(\"append label\")\n",
    "    raw1_reshaped[:,:,:,seq_len] = np.zeros((raw1_reshaped.shape[0],nbr_electrodes,nbr_electrodes))\n",
    "    raw2_reshaped[:,:,:,seq_len] = np.ones((raw2_reshaped.shape[0],nbr_electrodes,nbr_electrodes))\n",
    "\n",
    "    #return full dataset\n",
    "    print(\"return dataset\")\n",
    "    dataset = np.zeros((total_nbr_stim_per_file*nbr_files*2,nbr_electrodes,nbr_electrodes,seq_len+1))\n",
    "    dataset[:total_nbr_stim_per_file*nbr_files] = raw1_reshaped\n",
    "    dataset[total_nbr_stim_per_file*nbr_files:] = raw2_reshaped\n",
    "    return dataset.astype(np.float32)\n",
    "\n",
    "def recording_parameters(dirPath:str,offset:int):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "    dirPath: [str] path to directory\n",
    "    offset: [int] time delay before recording after a stimulus\n",
    "    OUTPUT:\n",
    "    total_nbr_stim_per_file: [int] number of electrodes time the number of stimulation per electrode\n",
    "    nbr_stim_per_electrode: [int] number of time the experiment is repeated throughout a file (9)\n",
    "    nbr_electrodes: [int] always 8. \n",
    "    nbr_neurospheres: [int] number of neurospheres considered (4 or 8)\n",
    "    seq_len: [int] length of of the data in the time dimension (3000)\n",
    "    \"\"\"\n",
    "    #file_data = load_raw_data(f'{dirPath}/exp_{0}_0_{offset}.npz')\n",
    "    file_data = load_raw_data(dirPath)\n",
    "    nbr_stim_per_electrode = file_data[1].shape[0]\n",
    "    nbr_electrodes = 8\n",
    "    nbr_neurospheres = int(file_data[1].shape[1]/8)\n",
    "    total_nbr_stim_per_file = nbr_stim_per_electrode*nbr_neurospheres\n",
    "    seq_len = file_data[1].shape[2]\n",
    "    return total_nbr_stim_per_file,nbr_stim_per_electrode,nbr_electrodes,nbr_neurospheres,seq_len\n",
    "\n",
    "def convertFlatRaw4x3x4x3(raw: np.array):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "    raw: [np.array] array of shape (N,1,8,8,M) with N the number of trials and M the length of the sequence\n",
    "    OUTPUT:\n",
    "    array4x3: [np.array] array of shape (N,1,4,3,4,3,M)\n",
    "    \"\"\"\n",
    "    map8 = np.array([[1,0],[0,1],[1,1],[1,2],[2,2],[2,1],[3,1],[2,0]])\n",
    "    array4x3 = torch.zeros((raw.shape[0],1,4,3,4,3,raw.shape[-1]),dtype=torch.float32)\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            array4x3[:,0,map8[i,0],map8[i,1],map8[j,0],map8[j,1],:] = raw[:,0,i,j,:]\n",
    "    return array4x3\n",
    "\n",
    "def getListFiles(dirPath):\n",
    "    listFiles = filter(os.path.isfile,glob.glob(f'{dirPath}/*.npz'))\n",
    "    listFiles = sorted(listFiles, key=os.path.getmtime)\n",
    "    return listFiles\n",
    "\n",
    "def read_in_data(dirPath):\n",
    "    offset_trigger_ms = 5\n",
    "    listFiles = getListFiles(dirPath)\n",
    "    dataset = create_array(dirPath, offset_trigger_ms, listFiles)\n",
    "    print(\"converting spatial position\")\n",
    "    dataset = convertFlatRaw4x3x4x3(dataset)\n",
    "    dataset = np.expand_dims(dataset,1)\n",
    "    return dataset\n",
    "\n",
    "# Replace 'your/directory/path' with the actual path where your .npz files are located\n",
    "directory_path = '/home/vincent/AAA_projects/UnlimitedResearchCooperative/Synthetic_Intelligence_Labs/human-cortical-organoid-signal-analysis/IntanToNWBtoNPZ/ElectricalSeries.npz'\n",
    "read_in_data(directory_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d48da8-745b-4393-9440-abefbe9a7bc6",
   "metadata": {},
   "source": [
    "# Second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45bd6bcf-4999-42ed-87f6-d67b588677de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pywt\n",
    "\n",
    "def prepare_electrical_series_data(filename, segment_length=3000):\n",
    "    # Load the data\n",
    "    loaded = np.load(filename)\n",
    "    data = loaded['data']  # Ensure 'data' is the correct key in your npz file\n",
    "\n",
    "    # Calculate the number of full segments\n",
    "    num_segments = data.shape[0] // segment_length\n",
    "\n",
    "    # Reshape the data into segments of 3000 data points, discard the remainder\n",
    "    reshaped_data = data[:num_segments * segment_length].reshape(num_segments, segment_length, -1)\n",
    "\n",
    "    return reshaped_data\n",
    "\n",
    "# Replace with your actual file path\n",
    "file_path = 'ElectricalSeries.npz'\n",
    "prepared_data = prepare_electrical_series_data(file_path)\n",
    "reshaped_data = prepared_data.transpose(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a58544ba-3231-4d97-8837-137e73ea83b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of reshaped data: (21, 64, 3000)\n",
      "First 5 rows of reshaped data:\n",
      "[[[ 2.5350000e-06 -5.0700000e-06  1.5600000e-06 ...  1.2558000e-04\n",
      "    1.2129000e-04  1.2675000e-04]\n",
      "  [ 7.2150001e-06  5.4600000e-06  5.6549998e-06 ...  1.2733499e-04\n",
      "    1.1934000e-04  1.2382500e-04]\n",
      "  [-3.9000000e-07 -2.9250000e-06  1.1505000e-05 ...  1.2480000e-04\n",
      "    1.2070500e-04  1.2148500e-04]\n",
      "  ...\n",
      "  [-2.1450001e-06  1.2480000e-05  8.1899998e-06 ...  1.2207000e-04\n",
      "    1.2675000e-04  1.2148500e-04]\n",
      "  [ 1.9500001e-06 -1.5600000e-06 -1.7550000e-06 ...  1.2499500e-04\n",
      "    1.1953500e-04  1.2285000e-04]\n",
      "  [ 9.7500003e-07  8.3850000e-06  9.5550004e-06 ...  1.1563500e-04\n",
      "    1.2850499e-04  1.2090000e-04]]\n",
      "\n",
      " [[ 1.1992500e-04  1.3571999e-04  1.2051000e-04 ...  3.1200001e-05\n",
      "    4.2315001e-05  3.2759999e-05]\n",
      "  [ 1.3162500e-04  1.2324000e-04  1.2480000e-04 ...  4.4655000e-05\n",
      "    3.3540000e-05  3.9194998e-05]\n",
      "  [ 1.2733499e-04  1.2714000e-04  1.2285000e-04 ...  3.7829999e-05\n",
      "    3.8220001e-05  4.2510001e-05]\n",
      "  ...\n",
      "  [ 1.1817000e-04  1.2382500e-04  1.2850499e-04 ...  3.2954998e-05\n",
      "    2.9055000e-05  3.7829999e-05]\n",
      "  [ 1.3591500e-04  1.1641500e-04  1.1953500e-04 ...  3.7245001e-05\n",
      "    3.7829999e-05  3.2565000e-05]\n",
      "  [ 1.1934000e-04  1.2655499e-04  1.2791999e-04 ...  3.2565000e-05\n",
      "    4.1924999e-05  3.5685000e-05]]\n",
      "\n",
      " [[ 3.6074998e-05  2.6129999e-05  4.2119998e-05 ... -1.5014999e-04\n",
      "   -1.5502500e-04 -1.5658500e-04]\n",
      "  [ 3.8804999e-05  2.6520000e-05  3.7635000e-05 ... -1.5307500e-04\n",
      "   -1.5229500e-04 -1.5677999e-04]\n",
      "  [ 2.8080000e-05  3.7635000e-05  3.8415001e-05 ... -1.5756000e-04\n",
      "   -1.5912000e-04 -1.6067999e-04]\n",
      "  ...\n",
      "  [ 4.1924999e-05  3.5490000e-05  3.8415001e-05 ... -1.5151499e-04\n",
      "   -1.5073500e-04 -1.5268500e-04]\n",
      "  [ 2.5545000e-05  3.8804999e-05  3.2175001e-05 ... -1.5756000e-04\n",
      "   -1.5307500e-04 -1.6867500e-04]\n",
      "  [ 2.3594999e-05  3.5490000e-05  4.0755000e-05 ... -1.5717000e-04\n",
      "   -1.5717000e-04 -1.5677999e-04]]\n",
      "\n",
      " [[-1.5580500e-04 -1.5073500e-04 -1.4859000e-04 ... -8.8920002e-05\n",
      "   -8.3264997e-05 -8.1509999e-05]\n",
      "  [-1.4976000e-04 -1.5580500e-04 -1.4917500e-04 ... -8.7554996e-05\n",
      "   -8.5799998e-05 -8.2095001e-05]\n",
      "  [-1.5307500e-04 -1.4917500e-04 -1.4781000e-04 ... -9.4185001e-05\n",
      "   -8.9114998e-05 -7.5855001e-05]\n",
      "  ...\n",
      "  [-1.5619500e-04 -1.5171000e-04 -1.6067999e-04 ... -9.2429997e-05\n",
      "   -9.4770003e-05 -8.7945002e-05]\n",
      "  [-1.4917500e-04 -1.5658500e-04 -1.5093001e-04 ... -8.3070001e-05\n",
      "   -8.8920002e-05 -8.2484999e-05]\n",
      "  [-1.5073500e-04 -1.5482999e-04 -1.5463500e-04 ... -8.6579996e-05\n",
      "   -7.9949998e-05 -8.1120001e-05]]\n",
      "\n",
      " [[-8.5799998e-05 -8.4824998e-05 -8.5214997e-05 ...  1.5502500e-04\n",
      "    1.4664000e-04  1.4079000e-04]\n",
      "  [-8.2095001e-05 -7.3515002e-05 -8.3070001e-05 ...  1.4039999e-04\n",
      "    1.4839500e-04  1.4391000e-04]\n",
      "  [-8.4239997e-05 -8.5605003e-05 -8.3849998e-05 ...  1.4449500e-04\n",
      "    1.5190500e-04  1.4196000e-04]\n",
      "  ...\n",
      "  [-9.2625000e-05 -8.4239997e-05 -8.5020001e-05 ...  1.5385500e-04\n",
      "    1.4800500e-04  1.4722500e-04]\n",
      "  [-7.3515002e-05 -8.5995001e-05 -9.4964998e-05 ...  1.4215500e-04\n",
      "    1.4664000e-04  1.5482999e-04]\n",
      "  [-7.7220000e-05 -7.9949998e-05 -7.5074997e-05 ...  1.4819999e-04\n",
      "    1.4429999e-04  1.5288001e-04]]]\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the reshaped data\n",
    "print(\"Shape of reshaped data:\", reshaped_data.shape)\n",
    "\n",
    "# Print the first 5 rows of the reshaped data\n",
    "print(\"First 5 rows of reshaped data:\")\n",
    "print(reshaped_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76415316-24a9-4f4c-bf02-e4096fa16567",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'t0 is not a file in the archive'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 117\u001b[0m\n\u001b[1;32m    115\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mElectricalSeries.npz\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    116\u001b[0m offset_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m--> 117\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset_ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m dataset \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(dataset, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    119\u001b[0m rng \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mdefault_rng(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 63\u001b[0m, in \u001b[0;36mcreate_array\u001b[0;34m(filename, offset)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_array\u001b[39m(filename: \u001b[38;5;28mstr\u001b[39m, offset: \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m     56\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m    INPUT:\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m    filename: [str] path to the .npz file\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m    dataset: [np.array] an array of shape (N,8,8,3001) containing the data\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m     raw_data \u001b[38;5;241m=\u001b[39m \u001b[43mload_raw_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     total_nbr_stim_per_file, nbr_stim_per_electrode, nbr_electrodes, nbr_neurospheres, seq_len \u001b[38;5;241m=\u001b[39m recording_parameters(raw_data, offset)\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# create two arrays of size (N,8,8,3001), each one corresponding to one of the class\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 14\u001b[0m, in \u001b[0;36mload_raw_data\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     12\u001b[0m raws \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, aname \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(list_array):\n\u001b[0;32m---> 14\u001b[0m     raws[i] \u001b[38;5;241m=\u001b[39m \u001b[43mloaded\u001b[49m\u001b[43m[\u001b[49m\u001b[43maname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m raws\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/numpy/lib/npyio.py:260\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mread(key)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 260\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not a file in the archive\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 't0 is not a file in the archive'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def load_raw_data(filename: str):\n",
    "    list_array = []\n",
    "    for i in range(8):\n",
    "        list_array.append(f't{i}')\n",
    "    \n",
    "    loaded = np.load(filename)\n",
    "    raws = {}\n",
    "    for i, aname in enumerate(list_array):\n",
    "        raws[i] = loaded[aname]\n",
    "    \n",
    "    return raws\n",
    "\n",
    "# convert (N,1,8,8,M) to (N,1,4,3,4,3,M)\n",
    "def convertFlatRaw4x3x4x3(raw: np.array):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "    raw: [np.array] array of shape (N,1,8,8,M) with N the number of trials and M the length of the sequence\n",
    "    OUTPUT:\n",
    "    array4x3: [np.array] array of shape (N,1,4,3,4,3,M)\n",
    "    \"\"\"\n",
    "    map8 = np.array([[1,0],[0,1],[1,1],[1,2],[2,2],[2,1],[3,1],[2,0]])\n",
    "    array4x3 = torch.zeros((raw.shape[0],1,4,3,4,3,raw.shape[-1]),dtype=torch.float32)\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            array4x3[:,0,map8[i,0],map8[i,1],map8[j,0],map8[j,1],:] = raw[:,0,i,j,:]\n",
    "    return array4x3\n",
    "\n",
    "# compute important parameters to create the dataset\n",
    "def recording_parameters(raw_data, offset:int):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "    raw_data: [dict] dictionary containing raw data arrays\n",
    "    offset: [int] time delay before recording after a stimulus\n",
    "    OUTPUT:\n",
    "    total_nbr_stim_per_file: [int] number of electrodes time the number of stimulation per electrode\n",
    "    nbr_stim_per_electrode: [int] number of time the experiment is repeated throughout a file (9)\n",
    "    nbr_electrodes: [int] always 8. \n",
    "    nbr_neurospheres: [int] number of neurospheres considered (4 or 8)\n",
    "    seq_len: [int] length of of the data in the time dimension (3000)\n",
    "    \"\"\"\n",
    "    # Assuming raw_data[1] is structured in a way that these indices make sense\n",
    "    nbr_stim_per_electrode = raw_data[1].shape[0]\n",
    "    nbr_electrodes = 8\n",
    "    nbr_neurospheres = int(raw_data[1].shape[1] / 8)\n",
    "    total_nbr_stim_per_file = nbr_stim_per_electrode * nbr_neurospheres\n",
    "    seq_len = raw_data[1].shape[2]\n",
    "    return total_nbr_stim_per_file, nbr_stim_per_electrode, nbr_electrodes, nbr_neurospheres, seq_len\n",
    "\n",
    "# create an array of shape (N,8,8,3000)\n",
    "def create_array(filename: str, offset: int):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "    filename: [str] path to the .npz file\n",
    "    offset: [int] time delay before recording after a stimulus\n",
    "    OUTPUT: \n",
    "    dataset: [np.array] an array of shape (N,8,8,3001) containing the data\n",
    "    \"\"\"\n",
    "    raw_data = load_raw_data(filename)\n",
    "    total_nbr_stim_per_file, nbr_stim_per_electrode, nbr_electrodes, nbr_neurospheres, seq_len = recording_parameters(raw_data, offset)\n",
    "\n",
    "\n",
    "    # create two arrays of size (N,8,8,3001), each one corresponding to one of the class\n",
    "    raw1_reshaped = np.zeros((total_nbr_stim_per_file*nbr_files,nbr_electrodes,nbr_electrodes,seq_len+1))\n",
    "    raw2_reshaped = np.zeros((total_nbr_stim_per_file*nbr_files,nbr_electrodes,nbr_electrodes,seq_len+1))\n",
    "\n",
    "    # fill these arrays with corresponding values from files\n",
    "    for start_exp_index in range(nbr_files):\n",
    "        print(f'experiment number:{start_exp_index}')\n",
    "        raw1 = load_raw_data(f'{dirPath}/exp_{start_exp_index}_0_{offset}.npz')\n",
    "        raw2 = load_raw_data(f'{dirPath}/exp_{start_exp_index}_1_{offset}.npz')\n",
    "\n",
    "        # reshape (80,8,8,3000)\n",
    "        raw1_one_file = np.zeros((total_nbr_stim_per_file,nbr_electrodes,nbr_electrodes,raw1[0].shape[2]))\n",
    "        raw2_one_file = np.zeros((total_nbr_stim_per_file,nbr_electrodes,nbr_electrodes,raw2[0].shape[2]))\n",
    "\n",
    "        # iterate through electrode stimulated and neurospheres\n",
    "        for electrode in range(nbr_electrodes):\n",
    "            #nbr_neurospheres = int(raw1[electrode].shape[1]/8)\n",
    "            # N: number of reptition of the stimulus\n",
    "            N = raw1[1].shape[0]\n",
    "            for i in range(nbr_neurospheres):\n",
    "                j = nbr_electrodes*i\n",
    "                raw1_one_file[N*i:N*(i+1),electrode] = raw1[electrode][:N,j:j+nbr_electrodes]\n",
    "                raw2_one_file[N*i:N*(i+1),electrode] = raw2[electrode][:N,j:j+nbr_electrodes]\n",
    "        raw1_reshaped[total_nbr_stim_per_file*start_exp_index:total_nbr_stim_per_file*(start_exp_index+1),:,:,:seq_len] = raw1_one_file\n",
    "        raw2_reshaped[total_nbr_stim_per_file*start_exp_index:total_nbr_stim_per_file*(start_exp_index+1),:,:,:seq_len] = raw2_one_file\n",
    "\n",
    "    # append label\n",
    "    print(\"append label\")\n",
    "    raw1_reshaped[:,:,:,seq_len] = np.zeros((raw1_reshaped.shape[0],nbr_electrodes,nbr_electrodes))\n",
    "    raw2_reshaped[:,:,:,seq_len] = np.ones((raw2_reshaped.shape[0],nbr_electrodes,nbr_electrodes))\n",
    "\n",
    "    #return full dataset\n",
    "    print(\"return dataset\")\n",
    "    dataset = np.zeros((total_nbr_stim_per_file*nbr_files*2,nbr_electrodes,nbr_electrodes,seq_len+1))\n",
    "    dataset[:total_nbr_stim_per_file*nbr_files] = raw1_reshaped\n",
    "    dataset[total_nbr_stim_per_file*nbr_files:] = raw2_reshaped\n",
    "    return dataset.astype(np.float32)\n",
    "\n",
    "\n",
    "# reduce the dimension of the recordings using wavelet transforms (3000->750)\n",
    "def wavelet_filter(data:np.array):\n",
    "    w1 = data[:,:,:,:,:-1]\n",
    "    (w1,_)=pywt.dwt(w1,wavelet='db4',axis=-1,mode='per')\n",
    "    (w1,_)=pywt.dwt(w1,wavelet='db4',axis=-1,mode='per')\n",
    "    return np.concatenate((w1,data[:,:,:,:,[-1]]),axis=-1)\n",
    "     \n",
    "\n",
    "# Use ElectricalSeries.npz file\n",
    "file_path = 'ElectricalSeries.npz'\n",
    "offset_ms = 5\n",
    "dataset = create_array(file_path, offset_ms)\n",
    "dataset = np.expand_dims(dataset, 1)\n",
    "rng = np.random.default_rng(seed=0)\n",
    "rng.shuffle(dataset, axis=0)\n",
    "dataset = wavelet_filter(dataset).astype(np.float32)\n",
    "\n",
    "print(\"Dataset Shape:\", dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c846977a-4d9c-4b5a-b76d-7ff7c4caba1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
